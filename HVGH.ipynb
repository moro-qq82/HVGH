{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HVGH",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P6_UboLT5Kq",
        "colab_type": "text"
      },
      "source": [
        "### Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9zhZgN5T2XC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VAE\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import time\n",
        "\n",
        "#HDP-GP-HSMM\n",
        "import random\n",
        "import math\n",
        "import sys\n",
        "import os\n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6f4WnrtVk4R",
        "colab_type": "code",
        "outputId": "42665bee-e32d-4db7-a70c-d3d1165df823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op4cGV1HoGza",
        "colab_type": "text"
      },
      "source": [
        "### VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_jAbb2LUV6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Variational_Auto_Encoder():\n",
        "  def __init__(self, input_dim, hidden_dims, latent_dim, kld_weight, epochs):\n",
        "    self.input_dim = input_dim\n",
        "    self.latent_dim = latent_dim\n",
        "    self.hidden_encoder_dim1 = hidden_dims[0]\n",
        "    self.hidden_encoder_dim2 = hidden_dims[1]\n",
        "    self.hidden_decoder_dim1 = hidden_dims[2]\n",
        "    self.hidden_decoder_dim2 = hidden_dims[3]\n",
        "    self.kld_weight = kld_weight\n",
        "    self.opt = Adam(lr=0.0001)\n",
        "    self.epochs = epochs\n",
        "\n",
        "    #encoder\n",
        "    logvar_prior = tf.keras.Input(shape=(self.latent_dim, ), name='logvar_prior')\n",
        "    mu_prior = tf.keras.Input(shape=(self.latent_dim, ), name='mu_prior')\n",
        "    inputs = tf.keras.layers.Input(shape=(self.input_dim, ), name='encoder_input')\n",
        "    hidden1= tf.keras.layers.Dense(self.hidden_encoder_dim1, activation='relu', name='enc1') (inputs)\n",
        "    hidden2 = tf.keras.layers.Dense(self.hidden_encoder_dim2, activation='relu', name='enc2') (hidden1)\n",
        "    z_mean = tf.keras.layers.Dense(self.latent_dim, activation='linear', name='z_mean')(hidden2)\n",
        "    z_log_var= tf.keras.layers.Dense(self.latent_dim, activation='linear', name='z_log_var')(hidden2)\n",
        "    z = tf.keras.layers.Lambda(self.sampling, name='z')([z_mean, z_log_var])\n",
        "    \n",
        "    enc_outputs = [z_mean, z_log_var, z]\n",
        "    encoder = tf.keras.models.Model(inputs, enc_outputs, name='encoder')\n",
        "\n",
        "    #decoder\n",
        "    latent_inputs = tf.keras.layers.Input(shape=(self.latent_dim,), name='z_sampling')\n",
        "    dec_hidden1 = tf.keras.layers.Dense(self.hidden_decoder_dim1, activation='relu', name='dec1') (latent_inputs)\n",
        "    dec_hidden2 = tf.keras.layers.Dense(self.hidden_decoder_dim2, activation='relu', name='dec2') (dec_hidden1)\n",
        "    outputs = tf.keras.layers.Dense(self.input_dim, activation='sigmoid') (dec_hidden2)\n",
        "\n",
        "    decoder = tf.keras.models.Model(latent_inputs, outputs, name='decoder')\n",
        "\n",
        "    #VAE(encoder+decoder)\n",
        "    inputs_ = [inputs, logvar_prior, mu_prior]\n",
        "    outputs_ = [ decoder(encoder(inputs)[2]), encoder(inputs)[0], encoder(inputs)[1] , encoder(inputs)[2]]  #output, mu, sigma\n",
        "    self.VAE = tf.keras.models.Model(inputs_, outputs_, name='VAE')\n",
        "    \n",
        "    #Loss\n",
        "    MSE = tf.reduce_sum( tf.math.squared_difference(K.flatten(outputs_[0]), K.flatten(inputs_[0])))\n",
        "    KLD = - 0.5 * tf.reduce_sum(1 + logvar_prior + z_log_var\n",
        "            - (tf.pow(z_mean - mu_prior, 2) \n",
        "            + tf.exp(z_log_var))/tf.exp(logvar_prior))\n",
        "    loss = tf.reduce_mean(MSE + KLD * self.kld_weight )\n",
        "\n",
        "    self.VAE.add_loss(loss)\n",
        "\n",
        "  def sampling(self, args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    \n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "  def compile(self):\n",
        "    self.VAE.compile(optimizer=self.opt)\n",
        "    #print (self.VAE.summary())\n",
        "\n",
        "  def learn(self, data, logvar_prior, mu_prior, verbose=True):\n",
        "    result = self.VAE.fit([data, logvar_prior, mu_prior] , epochs=1, verbose=verbose)\n",
        "    return result\n",
        "\n",
        "  def predict(self, data, logvar_prior, mu_prior, losses=False):\n",
        "    reconst, mu, sigma, z = self.VAE.predict([data, logvar_prior, mu_prior])\n",
        "    return reconst, mu, sigma, z\n",
        "\n",
        "  def plot(self, data, reconst, mu, sigma, z, losses, savepath):\n",
        "    if losses != False:\n",
        "      plt.title('loss')\n",
        "      plt.plot(np.arange(self.epochs), losses)\n",
        "      plt.savefig(savepath+'_loss.png')\n",
        "      plt.close()\n",
        "\n",
        "    plt.title(\"z_alldim\")\n",
        "    plt.plot(np.arange(mu.shape[0]), mu)\n",
        "    plt.savefig(savepath+'_z.png')\n",
        "    plt.close()\n",
        "\n",
        "    plt.title(\"z_hat_alldim\")\n",
        "    plt.plot(np.arange(mu.shape[0]), z)\n",
        "    plt.savefig(savepath+'_z_hat.png')\n",
        "    plt.close()\n",
        "\n",
        "    plt.title('data_alldim')\n",
        "    plt.plot(np.arange(mu.shape[0]), data)\n",
        "    plt.savefig(savepath+'_oridata.png')\n",
        "    plt.close()\n",
        "\n",
        "    plt.title('reconst_alldim')\n",
        "    plt.plot(np.arange(mu.shape[0]), reconst)\n",
        "    plt.savefig(savepath+'_reconst.png')\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8MoFn55VSQ5",
        "colab_type": "text"
      },
      "source": [
        "### GaussianProcess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seXBh3ADUy3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext Cython"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7NUmCGtU00V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%cython\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cdef extern from \"math.h\":\n",
        "    double exp(double)\n",
        "    double sqrt(double)\n",
        "    double log(double)\n",
        "\n",
        "cdef class GP:\n",
        "    cdef double beta\n",
        "    cdef int ns\n",
        "    cdef xt, yt\n",
        "    cdef double[:,:] i_cov\n",
        "    cdef double[:] param\n",
        "    cdef dict param_cache\n",
        "\n",
        "    cdef double covariance_func(self, double xi, double xj):\n",
        "        cdef double theta0 = 1.0\n",
        "        cdef double theta1 = 1.0\n",
        "        cdef double theta2 = 0\n",
        "        cdef double theta3 = 16.0\n",
        "        return theta0 * exp(-0.5 * theta1 * (xi - xj) * (xi - xj)) + theta2 + theta3 * xi * xj\n",
        "    \n",
        "    cdef double normpdf(self, double x, double mu, double sigma):\n",
        "        return 1./(sqrt(2*np.pi)*sigma)*exp(-0.5 * ((x - mu)/sigma)**2)\n",
        "\n",
        "    def __init__( self ):\n",
        "        self.beta = 10.0\n",
        "        self.param_cache = {}\n",
        "\n",
        "    def learn(self, xt, yt ):\n",
        "        cdef int i, j\n",
        "        self.xt = xt\n",
        "        self.yt = yt\n",
        "        self.ns = len(xt)\n",
        "\n",
        "        cdef double[:,:] cov = np.zeros((self.ns, self.ns))\n",
        "\n",
        "        for i in range(self.ns):\n",
        "            for j in range(self.ns):\n",
        "                cov[i,j] = self.covariance_func(xt[i], xt[j])\n",
        "                if i==j:\n",
        "                    cov[i,j] += 1/self.beta\n",
        "\n",
        "        self.i_cov = np.linalg.inv(cov)\n",
        "        self.param = np.dot(self.i_cov, self.yt)\n",
        "        self.param_cache.clear()\n",
        "\n",
        "    def plot(self, x):\n",
        "        mus, sigmas = self.predict( x.reshape(-1,1) )\n",
        "        plt.plot( x, mus )\n",
        "        \n",
        "        y_max = mus + np.sqrt(sigmas.flatten())\n",
        "        y_min = mus - np.sqrt(sigmas.flatten())\n",
        "\n",
        "        plt.fill_between(x, y_min, y_max, facecolor=\"lavender\" , alpha=0.9 , edgecolor=\"lavender\"  )\n",
        "        plt.plot(self.xt, self.yt)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def predict( self, x ):\n",
        "        mus = []\n",
        "        sigmas = []\n",
        "        n = len(x)\n",
        "        tt = [y - np.random.normal() / self.beta for y in self.yt]\n",
        "        for k in range(n):\n",
        "            v = np.zeros((self.ns))\n",
        "            for i in range(self.ns):\n",
        "                v[i] = self.covariance_func(x[k], self.xt[i])\n",
        "            c = self.covariance_func(x[k], x[k]) + 1.0 / self.beta\n",
        "            \n",
        "            mu = np.dot(v, np.dot(self.i_cov, tt))\n",
        "            sigma = c - np.dot(v, np.dot(self.i_cov, v))\n",
        "            \n",
        "            mus.append(mu)\n",
        "            sigmas.append(sigma)\n",
        "        \n",
        "        return np.array(mus), np.array(sigmas)\n",
        "    \n",
        "\n",
        "    cpdef double calc_lik_al( self, double[:] xs, double[:] ys ):\n",
        "        cdef int k,i\n",
        "        cdef int n = len(xs)\n",
        "        cdef double lik = 0\n",
        "        cdef int ns = self.ns\n",
        "        cdef double c,p,mu,sigma\n",
        "        cdef double[:] v= np.zeros((ns))\n",
        "\n",
        "        for k in range(n):\n",
        "            # 計算結果をキャッシュして使い回す\n",
        "            if xs[k] in self.param_cache:\n",
        "                mu, sigma = self.param_cache[ xs[k] ]\n",
        "            else:\n",
        "                v = np.zeros((ns))\n",
        "                for i in range(ns):\n",
        "                    v[i] = self.covariance_func(xs[k], self.xt[i])\n",
        "                c = self.covariance_func(xs[k], xs[k]) + 1.0 / self.beta\n",
        "                mu = np.dot(v, self.param)\n",
        "                sigma = c - np.dot(v, np.dot(self.i_cov, v))\n",
        "                \n",
        "                self.param_cache[ xs[k] ] = (mu, sigma)\n",
        "\n",
        "            p = self.normpdf( ys[k] , mu, sigma )\n",
        "            if p<=0:\n",
        "                p = 0.000000000001\n",
        "            lik += log( p )\n",
        "\n",
        "        return lik\n",
        "\n",
        "\n",
        "    def calc_lik( self, xs, ys ):\n",
        "      lik = self.calc_lik_al( xs, ys )\n",
        "      return lik"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTHGGvRRaUFb",
        "colab_type": "text"
      },
      "source": [
        "### logsum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmlzDvM2aV6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%cython\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.mlab as mlab\n",
        "import sys\n",
        "\n",
        "cdef extern from \"math.h\":\n",
        "    double log(double)\n",
        "    double exp(double)\n",
        "\n",
        "\n",
        "cpdef logsumexp( double[:,:] a ):\n",
        "    cdef double max_val = -sys.float_info.max\n",
        "    cdef double sum_exp = 0\n",
        "    cdef int I = a.shape[0]\n",
        "    cdef int J = a.shape[1]\n",
        "    \n",
        "    for i in range(I):\n",
        "        for j in range(J):\n",
        "            if max_val<a[i,j]:\n",
        "                max_val = a[i,j]\n",
        "                \n",
        "    for i in range(I):\n",
        "        for j in range(J):\n",
        "            sum_exp += exp( a[i,j] - max_val )\n",
        "    return log(sum_exp) + max_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAbp3HAOWnVW",
        "colab_type": "text"
      },
      "source": [
        "### multidim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8FhZCwMWp0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GPMD:\n",
        "    def __init__(self, dim):\n",
        "        self.__dim = dim\n",
        "        self.__gp = [ GP() for d in range(self.__dim) ]\n",
        "\n",
        "    def learn(self,x, y ):\n",
        "        y = np.array(y, dtype=np.float).reshape( (-1,self.__dim) )\n",
        "        x = np.array(x,dtype=np.float)\n",
        "\n",
        "        for d in range(self.__dim):\n",
        "            if len(y)!=0:\n",
        "                self.__gp[d].learn( x, y[:,d] )\n",
        "            else:\n",
        "                self.__gp[d].learn( x, [] )\n",
        "\n",
        "\n",
        "    def calc_lik(self, x, y, last = False):\n",
        "        lik = 0.0\n",
        "        mus = []\n",
        "        sigmas = []\n",
        "\n",
        "        if self.__dim==1:\n",
        "            y = np.asarray(y, dtype=np.float).reshape( (-1,self.__dim) )\n",
        "        for d in range(self.__dim):\n",
        "            lik += self.__gp[d].calc_lik( x , y[:,d] )\n",
        "            if last != False:\n",
        "              mu , sig = self.__gp[d].predict(x)\n",
        "              mus.append(mu)\n",
        "              sigmas.append(sig)\n",
        "\n",
        "        if last != False:\n",
        "          return lik, np.array(mus), np.array(sigmas)\n",
        "        else:\n",
        "          return lik\n",
        "\n",
        "    def plot(self, x ):\n",
        "        for d in range(self.__dim):\n",
        "            plt.subplot( self.__dim, 1, d+1 )\n",
        "\n",
        "            mus, sigmas = self.__gp[d].predict(x)\n",
        "            y_min = mus - sigmas*2\n",
        "            y_max = mus + sigmas*2\n",
        "\n",
        "            plt.fill_between( x, y_min, y_max, facecolor=\"lavender\" , alpha=0.9 , edgecolor=\"lavender\"  )\n",
        "            plt.plot(x, y_min, 'b--')\n",
        "            plt.plot(x, mus, 'b-')\n",
        "            plt.plot(x, y_max, 'b--')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ibGl4zBWqVg",
        "colab_type": "text"
      },
      "source": [
        "### segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0BfwNmBWtc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GPSegmentation():\n",
        "    def __init__(self, dim, gamma, alpha, initial_class):\n",
        "        self.dim = dim\n",
        "        self.numclass = initial_class\n",
        "        self.segmlen = 3\n",
        "        self.gps = [ GPMD(dim) for i in range(self.numclass) ]\n",
        "        self.segm_in_class= [ [] for i in range(self.numclass) ]\n",
        "        self.segmclass = {}\n",
        "        self.segments = []\n",
        "        self.trans_prob = np.ones( (1,1) )\n",
        "        self.trans_prob_bos = np.ones( 1 )\n",
        "        self.trans_prob_eos = np.ones( 1 )\n",
        "        self.all_numclass = []\n",
        "        self.counter = 0\n",
        "        self.is_initialized = False\n",
        "        \n",
        "        # parameters\n",
        "        self.MAX_LEN = 20\n",
        "        self.MIN_LEN = 3\n",
        "        self.AVE_LEN = 12\n",
        "        self.SKIP_LEN = 1\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.beta = np.ones(1)\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def load_data(self, zs, classfile=None ):\n",
        "        self.data = []\n",
        "        self.segments = []\n",
        "        self.is_initialized = False\n",
        "\n",
        "        for y in zs:\n",
        "            segm = []\n",
        "            self.data.append( np.array(y, dtype=np.float) )\n",
        "\n",
        "            i = 0\n",
        "            while i<len(y):\n",
        "                length = random.randint(self.MIN_LEN, self.MAX_LEN)\n",
        "\n",
        "                if i+length+1>=len(y):\n",
        "                    length = len(y)-i\n",
        "\n",
        "                segm.append( y[i:i+length+1] )\n",
        "\n",
        "                i+=length\n",
        "\n",
        "            self.segments.append( segm )\n",
        "\n",
        "            for i,s in enumerate(segm):\n",
        "                c = random.randint(0,self.numclass-1)\n",
        "                self.segmclass[id(s) ] = c\n",
        "\n",
        "        self.calc_trans_prob()\n",
        "\n",
        "\n",
        "    def load_model( self, basename ):\n",
        "        for c in range(self.numclass):\n",
        "            filename = basename + \"class%03d.npy\" % c\n",
        "            self.segm_in_class[c] = np.load( filename, allow_pickle=True)\n",
        "            self.update_gp( c )\n",
        "\n",
        "        self.trans_prob = np.load( basename+\"trans.npy\", allow_pickle=True )\n",
        "        self.trans_prob_bos = np.load( basename+\"trans_bos.npy\", allow_pickle=True )\n",
        "        self.trans_prob_eos = np.load( basename+\"trans_eos.npy\", allow_pickle=True )\n",
        "\n",
        "\n",
        "    def update_gp(self, c ):\n",
        "        datay = []\n",
        "        datax = []\n",
        "        for s in self.segm_in_class[c]:\n",
        "            datay += [ y for y in s ]\n",
        "            datax += range(len(s))\n",
        "\n",
        "        self.gps[c].learn( datax, datay )\n",
        "\n",
        "\n",
        "    def calc_emission_logprob( self, c, segm ):\n",
        "        gp = self.gps[c]\n",
        "        slen = len(segm)\n",
        "\n",
        "        if len(segm) > 2:\n",
        "            log_plen = (slen*math.log(self.AVE_LEN) + (-self.AVE_LEN)*math.log(math.e)) - (sum(np.log(np.arange(1,slen+1))))\n",
        "            p = gp.calc_lik( np.arange(len(segm), dtype=np.float) , segm )\n",
        "            return p + log_plen\n",
        "        else:\n",
        "            return math.log(1.0e-100)\n",
        "\n",
        "    def save_model(self, basename ):\n",
        "        if not os.path.exists(basename):\n",
        "            os.mkdir( basename )\n",
        "\n",
        "        for n,segm in enumerate(self.segments):\n",
        "            classes = []\n",
        "            cut_points = []\n",
        "            for s in segm:\n",
        "                c = self.segmclass[id(s)]\n",
        "                classes += [ c for i in range(len(s)) ]\n",
        "                cut_points += [0] * len(s)\n",
        "                cut_points[-1] = 1\n",
        "            np.savetxt( basename+\"segm%03d.txt\" % n, np.vstack([classes,cut_points]).T, fmt=str(\"%d\") )\n",
        "\n",
        "        for c in range(len(self.gps)):\n",
        "            for d in range(self.dim):\n",
        "                plt.clf()\n",
        "                for data in self.segm_in_class[c]:\n",
        "                    if self.dim==1:\n",
        "                        plt.plot( range(len(data)), data, \"o-\" )\n",
        "                    else:\n",
        "                        plt.plot( range(len(data[:,d])), data[:,d], \"o-\" )\n",
        "                    plt.ylim( -1, 1 )\n",
        "                plt.savefig( basename+\"class%03d_dim%03d.png\" % (c, d) )\n",
        "                plt.close()\n",
        "\n",
        "        np.save( basename + \"trans.npy\" , self.trans_prob  )\n",
        "        np.save( basename + \"trans_bos.npy\" , self.trans_prob_bos )\n",
        "        np.save( basename + \"trans_eos.npy\" , self.trans_prob_eos )\n",
        "        np.save( basename + \"all_class.npy\", self.segm_in_class[c])\n",
        "\n",
        "        for c in range(self.numclass):\n",
        "            np.save( basename+\"class%03d.npy\" % c, self.segm_in_class[c] )\n",
        "\n",
        "        return self.numclass\n",
        "\n",
        "\n",
        "    def forward_filtering(self, d ):\n",
        "        T = len(d)\n",
        "        log_a = np.log( np.zeros( (len(d), self.MAX_LEN, self.numclass) )  + 1.0e-100 ) \n",
        "        valid = np.zeros( (len(d), self.MAX_LEN, self.numclass) ) \n",
        "        z = np.ones( T )\n",
        "\n",
        "        for t in range(T):\n",
        "            for k in range(self.MIN_LEN,self.MAX_LEN,self.SKIP_LEN):\n",
        "                if t-k<0:\n",
        "                    break\n",
        "\n",
        "                segm = d[t-k:t+1]\n",
        "                for c in range(self.numclass):\n",
        "                    out_prob = self.calc_emission_logprob( c, segm )\n",
        "                    foward_prob = 0.0\n",
        "\n",
        "                    tt = t-k-1\n",
        "                    if tt>=0:\n",
        "                        foward_prob = logsumexp( log_a[tt,:,:] + z[tt] + np.log(self.trans_prob[:,c]) ) + out_prob\n",
        "                    else:\n",
        "                        foward_prob = out_prob + math.log(self.trans_prob_bos[c])\n",
        "\n",
        "                    if t==T-1:\n",
        "                        foward_prob += math.log(self.trans_prob_eos[c])\n",
        "\n",
        "                    log_a[t,k,c] = foward_prob\n",
        "                    valid[t,k,c] = 1.0\n",
        "                    if math.isnan(foward_prob):\n",
        "                        print( \"a[t=%d,k=%d,c=%d] became NAN!!\" % (t,k,c) )\n",
        "                        sys.exit(-1)\n",
        "\n",
        "            if t-self.MIN_LEN>=0:\n",
        "                z[t] = logsumexp( log_a[t,:,:] )\n",
        "                log_a[t,:,:] -= z[t]\n",
        "\n",
        "        return np.exp(log_a)*valid\n",
        "\n",
        "\n",
        "    def sample_idx(self, prob ):\n",
        "        accm_prob = [0,] * len(prob)\n",
        "        for i in range(len(prob)):\n",
        "            accm_prob[i] = prob[i] + accm_prob[i-1]\n",
        "\n",
        "        rnd = random.random() * accm_prob[-1]\n",
        "        for i in range(len(prob)):\n",
        "            if rnd <= accm_prob[i]:\n",
        "                return i\n",
        "\n",
        "\n",
        "    def backward_sampling(self, a, d):\n",
        "        T = a.shape[0]\n",
        "        t = T-1\n",
        "\n",
        "        segm = []\n",
        "        segm_class = []\n",
        "\n",
        "        c = -1\n",
        "        while True:\n",
        "            if t==T-1:\n",
        "                transp = self.trans_prob_eos\n",
        "            else:\n",
        "                transp = self.trans_prob[:,c]\n",
        "            \n",
        "            idx = self.sample_idx( a[t].reshape( self.MAX_LEN*self.numclass ))\n",
        "\n",
        "            k = int(idx/self.numclass)\n",
        "            c = idx % self.numclass\n",
        "\n",
        "            if t-k-1<=0:\n",
        "                s = d[0:t+1]\n",
        "            else:\n",
        "                s = d[t-k:t+1]\n",
        "\n",
        "            segm.insert( 0, s )\n",
        "            segm_class.insert( 0, c )\n",
        "\n",
        "            t = t-k-1\n",
        "\n",
        "            if t<=0:\n",
        "                break\n",
        "\n",
        "        return segm, segm_class\n",
        "\n",
        "\n",
        "    def calc_trans_prob( self ):\n",
        "        self.trans_prob = np.zeros( (self.numclass,self.numclass) )\n",
        "        self.trans_prob_bos = np.zeros( self.numclass )\n",
        "        self.trans_prob_eos = np.zeros( self.numclass )\n",
        "\n",
        "        for n,segm in enumerate(self.segments):\n",
        "            if id(segm[0]) in self.segmclass:\n",
        "                c_begin = self.segmclass[ id(segm[0]) ]\n",
        "                self.trans_prob_bos[c_begin]+=1\n",
        "\n",
        "            if id(segm[-1]) in self.segmclass:\n",
        "                c_end = self.segmclass[ id(segm[-1]) ]\n",
        "                self.trans_prob_eos[c_end]+=1\n",
        "\n",
        "            for i in range(1,len(segm)):\n",
        "                try:\n",
        "                    cc = self.segmclass[ id(segm[i-1]) ]\n",
        "                    c = self.segmclass[ id(segm[i]) ]\n",
        "                except KeyError:\n",
        "\n",
        "                    continue\n",
        "                self.trans_prob[cc,c] += 1\n",
        "\n",
        "        self.trans_prob_bos += self.alpha * self.beta\n",
        "        self.trans_prob_eos += self.alpha * self.beta\n",
        "\n",
        "        for c in range(self.numclass):\n",
        "            self.trans_prob[c,:] += self.alpha * self.beta\n",
        "\n",
        "        self.trans_prob = self.trans_prob / self.trans_prob.sum(1).reshape(self.numclass,1)\n",
        "        self.trans_prob_bos = self.trans_prob_bos / np.sum( self.trans_prob_bos )\n",
        "        self.trans_prob_eos = self.trans_prob_eos / np.sum( self.trans_prob_eos )\n",
        "\n",
        "\n",
        "    def sample_num_states(self):\n",
        "\n",
        "        # calculate u\n",
        "        u = []\n",
        "        for n,segm in enumerate(self.segments):\n",
        "            c = self.segmclass[ id(segm[0]) ]\n",
        "            p = self.trans_prob_bos[c]\n",
        "            u.append( random.random() * p )\n",
        "\n",
        "            c = self.segmclass[ id(segm[-1]) ]\n",
        "            p = self.trans_prob_eos[c]\n",
        "            u.append( random.random() * p )\n",
        "\n",
        "            for i in range(1,len(segm)):\n",
        "                cc = self.segmclass[ id(segm[i-1]) ]\n",
        "                c = self.segmclass[ id(segm[i]) ]\n",
        "                p = self.trans_prob[cc,c]\n",
        "                u.append( random.random() * p )\n",
        "\n",
        "        # remove \n",
        "        beta = list( self.beta )\n",
        "        for c in range(self.numclass)[::-1]:\n",
        "            if len(self.segm_in_class[c])==0:\n",
        "                self.numclass -= 1\n",
        "                self.gps.pop()\n",
        "                self.segm_in_class.pop()\n",
        "                beta[-2] += beta[-1]\n",
        "                beta.pop()\n",
        "                #print (\"pop!\")\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        u_min = np.min( u )\n",
        "\n",
        "        N = 0\n",
        "        for c in range(self.numclass):\n",
        "            N += len(self.segm_in_class[c])\n",
        "\n",
        "        while self.alpha*beta[-1]/N > u_min:\n",
        "            stick_len = beta[-1]\n",
        "            rnd = np.random.beta(1,self.gamma)\n",
        "            beta[-1] = stick_len * rnd\n",
        "            beta.append( stick_len * (1-rnd) )\n",
        "            self.numclass += 1\n",
        "            self.gps.append( GPMD(self.dim) )\n",
        "            self.segm_in_class.append([])\n",
        "\n",
        "        self.beta = np.array( beta )\n",
        "\n",
        "        self.all_numclass.append(self.numclass)\n",
        "    \n",
        "    \n",
        "    # If list.remove( elem ), ValueError.\n",
        "    def remove_ndarray(self, lst, elem ):\n",
        "        l = len(elem)\n",
        "        for i,e in enumerate(lst):\n",
        "            if len(e)!=l:\n",
        "                continue\n",
        "            if (e==elem).all():\n",
        "                lst.pop(i)\n",
        "                return\n",
        "        raise ValueError( \"ndarray is not found!!\" )\n",
        "\n",
        "    def learn(self):\n",
        "        if self.is_initialized==False:\n",
        "            # learn GP\n",
        "            for i in range(len(self.segments)):\n",
        "                for s in self.segments[i]:\n",
        "                    c = self.segmclass[id(s)]\n",
        "                    self.segm_in_class[c].append( s )\n",
        "\n",
        "            # learn each classes\n",
        "            for c in range(self.numclass):\n",
        "                self.update_gp( c )\n",
        "\n",
        "            self.is_initialized = True\n",
        "\n",
        "        self.update(True)\n",
        "\n",
        "    def recog(self):\n",
        "        self.update(False)\n",
        "\n",
        "    def update(self, learning_phase=True ):\n",
        "\n",
        "        for i in range(len(self.segments)):\n",
        "            if learning_phase:\n",
        "                print (\"slice sampling\")\n",
        "                self.sample_num_states()\n",
        "            \n",
        "            d = self.data[i]\n",
        "            segm = self.segments[i]\n",
        "\n",
        "            for s in segm:\n",
        "                c = self.segmclass[id(s)]\n",
        "                self.segmclass.pop( id(s) )\n",
        "\n",
        "                if learning_phase:\n",
        "                    # update parameter\n",
        "                    self.remove_ndarray( self.segm_in_class[c], s )\n",
        "\n",
        "            if learning_phase:\n",
        "                # update GP\n",
        "                for c in range(self.numclass):\n",
        "                    self.update_gp( c )\n",
        "\n",
        "                # update transition probability\n",
        "                self.calc_trans_prob()\n",
        "\n",
        "            start = time.clock()\n",
        "            print( \"forward...\", end=\"\")\n",
        "            a = self.forward_filtering( d )\n",
        "\n",
        "            print( \"backward...\", end=\"\" )\n",
        "            segm, segm_class = self.backward_sampling( a, d )\n",
        "            print( time.clock()-start, \"sec\" )\n",
        "\n",
        "            print( \"Number of classified segments: [\", end=\"\")\n",
        "            for s in self.segm_in_class:\n",
        "                print( len(s), end=\" \" )\n",
        "            print( \"]\" )\n",
        "\n",
        "\n",
        "            self.segments[i] = segm\n",
        "\n",
        "            for s,c in zip( segm, segm_class ):\n",
        "                self.segmclass[id(s)] = c\n",
        "\n",
        "                # update parameter\n",
        "                if learning_phase:\n",
        "                    self.segm_in_class[c].append(s)\n",
        "\n",
        "            if learning_phase:\n",
        "                # update GP\n",
        "                for c in range(self.numclass):\n",
        "                    self.update_gp( c )\n",
        "\n",
        "                # update transition probability\n",
        "                self.calc_trans_prob()\n",
        "        return\n",
        "\n",
        "\n",
        "    def calc_lik(self, last=False):\n",
        "        liks = 0\n",
        "        mus_all = []\n",
        "        sigmas_all = []\n",
        "\n",
        "        for segm in self.segments:\n",
        "            # last\n",
        "            if last != False:\n",
        "              mus = [[] for i in range(self.dim)]\n",
        "              sigmas = [[] for i in range(self.dim)]\n",
        "\n",
        "            for n, s in enumerate(segm):\n",
        "                c = self.segmclass[id(s)]\n",
        "                liks += self.gps[c].calc_lik( np.arange(len(s),dtype=np.float) , np.array(s) )\n",
        "                \n",
        "                # last\n",
        "                if last != False:\n",
        "                  lik, mu, sig = self.gps[c].calc_lik( np.arange(len(s), dtype=np.float) , s , last)\n",
        "                  if n == 0:\n",
        "                    for dd in range(self.dim):\n",
        "                        mus[dd] = mu[dd]\n",
        "                        sigmas[dd] = sig[dd]\n",
        "                  else:\n",
        "                    for dd in range(self.dim):\n",
        "                        mus[dd] = np.concatenate([mus[dd], mu[dd]])\n",
        "                        sigmas[dd] = np.concatenate([sigmas[dd], sig[dd]])\n",
        "\n",
        "                  liks += lik\n",
        "\n",
        "            # last\n",
        "            if last != False:\n",
        "              mus_all.append((np.array(mus).T).astype(np.float32))\n",
        "              sigmas_all.append(np.log((np.array(sigmas).T).astype(np.float32)))\n",
        "\n",
        "        #last\n",
        "        if last != False:\n",
        "          return liks, mus_all, sigmas_all\n",
        "        else:\n",
        "          return liks\n",
        "\n",
        "    \n",
        "    def get_num_class(self):\n",
        "        n = 0\n",
        "        for c in range(self.numclass):\n",
        "            if len(self.segm_in_class[c])!=0:\n",
        "                n += 1\n",
        "        return n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w21E05WtWt66",
        "colab_type": "text"
      },
      "source": [
        "### main_segm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws1Ve9DCWv1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learn( zs, savedir, dim, gamma, eta, initial_class ):\n",
        "    gpsegm = GPSegmentation( dim, gamma, eta, initial_class)\n",
        "\n",
        "    gpsegm.load_data( zs )\n",
        "    liks = []\n",
        "\n",
        "    start_time = time.time()\n",
        "    #iteration (default: 10)\n",
        "    for it in range( 8 ):\n",
        "        print( \"-----\", it, \"-----\" )\n",
        "        gpsegm.learn()\n",
        "        numclass = gpsegm.save_model( savedir )\n",
        "        print( \"lik =\", gpsegm.calc_lik() )\n",
        "        liks.append(gpsegm.calc_lik())\n",
        "    #print (\"liks: \",liks)\n",
        "    print ('%.2f[sec]'%(time.time()-start_time))\n",
        "    \n",
        "    #plot liks\n",
        "    plt.clf()\n",
        "    plt.plot( range(len(liks)), liks )\n",
        "    plt.savefig( os.path.join( savedir,\"liks.png\") )\n",
        "\n",
        "    lik, mu, sigma = gpsegm.calc_lik(last=True)\n",
        "    return numclass, np.array(mu), np.array(sigma)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtlVr6eDTiiq",
        "colab_type": "text"
      },
      "source": [
        "### main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MZ7KwpjVAzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    hidden_dim = [40,20,20,40]\n",
        "    latent_dim= 3\n",
        "    \n",
        "    #weight of KLD\n",
        "    kld_weight = 0.9\n",
        "    #number of learn of vae in an iteration \n",
        "    epochs = 100\n",
        "    #mutual learning loop (VAE and HDP-GP-HSMM)\n",
        "    iteration = 10\n",
        "\n",
        "    data_ = []\n",
        "    batch_sizes = []\n",
        "    logvar_priors = []\n",
        "    mu_priors = []\n",
        "\n",
        "    #pathの変更をしてください．\n",
        "    files =  [ \"chickendance%03d.txt\" % j for j in range(4) ]\n",
        "    for f in files:\n",
        "      y = np.loadtxt(f, dtype=np.float)[::15]\n",
        "      #print (len(y))\n",
        "      data_.append( y )\n",
        "      batch_sizes.append( int(len(y)/4) )\n",
        "\n",
        "      logvar_priors.append( np.array( np.zeros( (len(y),latent_dim) ), dtype='float32' ) )\n",
        "      mu_priors.append( np.array( np.zeros( (len(y),latent_dim) ), dtype='float32' ) )\n",
        "\n",
        "    input_dim=len(data_[0][0])\n",
        "\n",
        "    #HDP-GP-HSMM parameters\n",
        "    gamma = 1.0\n",
        "    eta = 10.0\n",
        "    initial_class = 1\n",
        "\n",
        "    #define VAE\n",
        "    vae = Variational_Auto_Encoder(input_dim, hidden_dim, latent_dim, kld_weight, epochs)\n",
        "    vae.compile()\n",
        "\n",
        "    path = ('HVGH/')\n",
        "    #learn VAE and HSP-GP-HSMM\n",
        "    for ite in range(iteration):\n",
        "      print (\"*--------------iteration:%03d--------------*\"%ite)\n",
        "      zs = []\n",
        "      for n, data in enumerate(data_):\n",
        "        losses = []\n",
        "        #start_time = time.time()\n",
        "\n",
        "        for e in range(epochs):\n",
        "          idx = np.random.choice(range(0, len(data)), batch_sizes[n])\n",
        "          result = vae.learn(data[idx], logvar_priors[n][idx], mu_priors[n][idx], verbose=0)\n",
        "          losses.append(result.history['loss'])\n",
        "        \n",
        "        #print ('%.2f[sec]'%(time.time()-start_time))\n",
        "        #predicts\n",
        "        reconst, mu, sigma, z = vae.predict(data, logvar_priors[n], mu_priors[n], losses)\n",
        "        savepath = (path+'HVGHlearn/%03d/'%ite)\n",
        "        if not os.path.exists(savepath):\n",
        "          os.makedirs(savepath)\n",
        "        savepath_ = (savepath + 'data_%03d'%n)\n",
        "        vae.plot(data, reconst, mu, sigma, z, losses, savepath_)\n",
        "        print ('VAE learned', 'iteration:', ite, 'data:', n)\n",
        "\n",
        "        zs.append(np.array(mu))\n",
        "        np.savetxt(savepath_+'_z.txt', mu)\n",
        "        \n",
        "      #vae.save_weights(savepath+'vae_weights.hdf5')\n",
        "      vae.VAE.save_weights(savepath+'vae_weights.hdf5')\n",
        "\n",
        "      # HDP-GP-HSMM\n",
        "      #learn\n",
        "      z_dim = len(zs[0][0])\n",
        "      recog_initial_class, mu_priors, logvar_priors = learn( zs, savepath, z_dim, gamma, eta, initial_class )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3NIpYNyTTjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFb5S7jVRYLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}